{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Introduction \n",
    "\n",
    "This is a feature engineering notebook for the DonorsChoose.org Application Screening competition. The objective is to predict whether teachers' project proposals are accepted or rejected. In this notebook, I have described different types of features that can be engineered with the given dataset. These features can be used in the classification models.  \n",
    "\n",
    "### Contents\n",
    "\n",
    "1. Aggregated Features\n",
    "2. Date-Time Features\n",
    "3. Text Based Features\n",
    "4. NLP Based Features\n",
    "5. TF-IDF Features\n",
    "    - Word Level TF-IDF\n",
    "    - Character Level TF-IDF\n",
    "6. Word Embedding Features\n",
    "7. Topic Modelling Features\n",
    "8. Count Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Important !!\n",
    "# Set small_run = False, to run this feature engineering notebook for entire dataframe\n",
    "# Setting small_run = True, runs the notebook only for top 100 rows of the dataframe\n",
    "# I have added this flag so that this notebook can be executed in kaggle kernal\n",
    "\n",
    "run_for_small_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.layers import Input, Embedding\n",
    "\n",
    "from nltk import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import string\n",
    "\n",
    "stop_words = ['a']\n",
    "# stop_words = list(set(stopwords.words('english')))\n",
    "warnings.filterwarnings('ignore')\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# read data files \n",
    "\n",
    "id_column = \"id\"\n",
    "missing_token = \" UNK \"\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\", parse_dates=[\"project_submitted_datetime\"])\n",
    "test = pd.read_csv(\"data/test.csv\", parse_dates=[\"project_submitted_datetime\"])\n",
    "rc = pd.read_csv(\"data/resources.csv\").fillna(missing_token)\n",
    "\n",
    "df = pd.concat([train, test], axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Aggregated Features\n",
    "\n",
    "Features obtained by aggregating the fields from resources data and the training data\n",
    "\n",
    "- **Feature 1,2,3 - Min Price, Max Price, Mean Price**: Min, Max, and Mean value of Price of resources requested.\n",
    "\n",
    "- **Feature 4,5,6 - Min Quantity, Max Quantity, Mean Quantity**: Min, Max, and Mean value of Quantity of resources requested.\n",
    "\n",
    "- **Feature 7,8,9 - Min Total Price, Max Total Price, Mean Total Price**: Min, Max, and Mean value of Total Price of resources requested.\n",
    "\n",
    "- **Feature 10,11,12 - Sum of Total Price**: Total price of all the resoruces requested by the teacher in a proposal\n",
    "\n",
    "- **Feature 13 - Items Requested**: Total unique number of items requested by the teacher in a proposal\n",
    "\n",
    "- **Feature 14 - Quantity**: Total number of quantities requested by the teacher in a proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine descriptions\n"
     ]
    }
   ],
   "source": [
    "rc['total_price'] = rc['quantity']*rc['price']\n",
    "agg_rc = rc.groupby('id').agg({'description':'count', 'quantity':'sum', 'price':'sum', 'total_price':'sum'}).rename(columns={'description':'items'})\n",
    "\n",
    "for func in ['min', 'max', 'mean']:\n",
    "    agg_rc_temp = rc.groupby('id').agg({'quantity':func, 'price':func, 'total_price':func}).rename(columns={'quantity':func+'_quantity', 'price':func+'_price', 'total_price':func+'_total_price'}).fillna(0)\n",
    "    agg_rc = agg_rc.join(agg_rc_temp)\n",
    "\n",
    "print \"combine descriptions\"\n",
    "agg_rc = agg_rc.join(rc.groupby('id').agg({'description':lambda x:' '.join(x.values.astype(str))}).rename(columns={'description':'resource_description'}))\n",
    "df = df.join(agg_rc, on='id')\n",
    "\n",
    "\n",
    "if run_for_small_data:\n",
    "    df = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>items</th>\n",
       "      <th>quantity</th>\n",
       "      <th>min_price</th>\n",
       "      <th>min_total_price</th>\n",
       "      <th>min_quantity</th>\n",
       "      <th>max_price</th>\n",
       "      <th>max_total_price</th>\n",
       "      <th>max_quantity</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>mean_total_price</th>\n",
       "      <th>mean_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.98</td>\n",
       "      <td>899.94</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>149.99</td>\n",
       "      <td>449.97</td>\n",
       "      <td>3</td>\n",
       "      <td>149.99</td>\n",
       "      <td>449.97</td>\n",
       "      <td>3</td>\n",
       "      <td>149.990</td>\n",
       "      <td>449.970</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>20</td>\n",
       "      <td>20.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469.99</td>\n",
       "      <td>469.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>469.99</td>\n",
       "      <td>469.99</td>\n",
       "      <td>1</td>\n",
       "      <td>469.99</td>\n",
       "      <td>469.99</td>\n",
       "      <td>1</td>\n",
       "      <td>469.990</td>\n",
       "      <td>469.990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>684.47</td>\n",
       "      <td>684.47</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18.95</td>\n",
       "      <td>18.95</td>\n",
       "      <td>1</td>\n",
       "      <td>354.99</td>\n",
       "      <td>354.99</td>\n",
       "      <td>1</td>\n",
       "      <td>136.894</td>\n",
       "      <td>136.894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355.50</td>\n",
       "      <td>711.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>355.50</td>\n",
       "      <td>711.00</td>\n",
       "      <td>2</td>\n",
       "      <td>355.50</td>\n",
       "      <td>711.00</td>\n",
       "      <td>2</td>\n",
       "      <td>355.500</td>\n",
       "      <td>711.000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>207.82</td>\n",
       "      <td>727.36</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>103.90</td>\n",
       "      <td>311.76</td>\n",
       "      <td>3</td>\n",
       "      <td>103.92</td>\n",
       "      <td>415.60</td>\n",
       "      <td>4</td>\n",
       "      <td>103.910</td>\n",
       "      <td>363.680</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111.00</td>\n",
       "      <td>414.02</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>14.99</td>\n",
       "      <td>29.98</td>\n",
       "      <td>2</td>\n",
       "      <td>96.01</td>\n",
       "      <td>384.04</td>\n",
       "      <td>4</td>\n",
       "      <td>55.500</td>\n",
       "      <td>207.010</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69.13</td>\n",
       "      <td>414.78</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>69.13</td>\n",
       "      <td>414.78</td>\n",
       "      <td>6</td>\n",
       "      <td>69.13</td>\n",
       "      <td>414.78</td>\n",
       "      <td>6</td>\n",
       "      <td>69.130</td>\n",
       "      <td>414.780</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79.95</td>\n",
       "      <td>319.80</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>79.95</td>\n",
       "      <td>319.80</td>\n",
       "      <td>4</td>\n",
       "      <td>79.95</td>\n",
       "      <td>319.80</td>\n",
       "      <td>4</td>\n",
       "      <td>79.950</td>\n",
       "      <td>319.800</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59.88</td>\n",
       "      <td>119.76</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>59.88</td>\n",
       "      <td>119.76</td>\n",
       "      <td>2</td>\n",
       "      <td>59.88</td>\n",
       "      <td>119.76</td>\n",
       "      <td>2</td>\n",
       "      <td>59.880</td>\n",
       "      <td>119.760</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  total_price  items  quantity  min_price  min_total_price  \\\n",
       "0  299.98       899.94      2         6     149.99           449.97   \n",
       "1   20.00       400.00      1        20      20.00           400.00   \n",
       "2  469.99       469.99      1         1     469.99           469.99   \n",
       "3  684.47       684.47      5         5      18.95            18.95   \n",
       "4  355.50       711.00      1         2     355.50           711.00   \n",
       "5  207.82       727.36      2         7     103.90           311.76   \n",
       "6  111.00       414.02      2         6      14.99            29.98   \n",
       "7   69.13       414.78      1         6      69.13           414.78   \n",
       "8   79.95       319.80      1         4      79.95           319.80   \n",
       "9   59.88       119.76      1         2      59.88           119.76   \n",
       "\n",
       "   min_quantity  max_price  max_total_price  max_quantity  mean_price  \\\n",
       "0             3     149.99           449.97             3     149.990   \n",
       "1            20      20.00           400.00            20      20.000   \n",
       "2             1     469.99           469.99             1     469.990   \n",
       "3             1     354.99           354.99             1     136.894   \n",
       "4             2     355.50           711.00             2     355.500   \n",
       "5             3     103.92           415.60             4     103.910   \n",
       "6             2      96.01           384.04             4      55.500   \n",
       "7             6      69.13           414.78             6      69.130   \n",
       "8             4      79.95           319.80             4      79.950   \n",
       "9             2      59.88           119.76             2      59.880   \n",
       "\n",
       "   mean_total_price  mean_quantity  \n",
       "0           449.970            3.0  \n",
       "1           400.000           20.0  \n",
       "2           469.990            1.0  \n",
       "3           136.894            1.0  \n",
       "4           711.000            2.0  \n",
       "5           363.680            3.5  \n",
       "6           207.010            3.0  \n",
       "7           414.780            6.0  \n",
       "8           319.800            4.0  \n",
       "9           119.760            2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['price', 'total_price', 'items', 'quantity', 'min_price', 'min_total_price', 'min_quantity', \n",
    "    'max_price', 'max_total_price', 'max_quantity', 'mean_price', 'mean_total_price', 'mean_quantity']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Datetime Features \n",
    "\n",
    "Features extracted from project submitted datetime\n",
    "\n",
    "- **Feature 15 - Year of Submission**: Value of year when the proposal was submitted\n",
    "- **Feature 16 - Month of Submission**: Month number (values between 1 to 12) when the proposal was submitted\n",
    "- **Feature 17 - Week Day of Submission**: Week Day value (values between 1 to 7) when the proposal was submitted\n",
    "- **Feature 18 - Hour of Submission**: Value of time hour (values between 0 to 23) when the proposal was submitted\n",
    "- **Feature 19 - Year Day of Submission**: Year Day (values between 1 to 365) when the proposal was submitted\n",
    "- **Feature 20 - Month Day of Submission**: Month Day (values between 1 to 31) when the proposal was submitted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting datetime features using datetime module \n",
    "df[\"Year\"] = df[\"project_submitted_datetime\"].dt.year\n",
    "df[\"Month\"] = df[\"project_submitted_datetime\"].dt.month\n",
    "df['Weekday'] = df['project_submitted_datetime'].dt.weekday\n",
    "df[\"Hour\"] = df[\"project_submitted_datetime\"].dt.hour\n",
    "df[\"Month_Day\"] = df['project_submitted_datetime'].dt.day\n",
    "df[\"Year_Day\"] = df['project_submitted_datetime'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month_Day</th>\n",
       "      <th>Year_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Weekday  Hour  Month_Day  Year_Day\n",
       "0  2016     11        4    14         18       323\n",
       "1  2017      4        2    15         26       116\n",
       "2  2017      1        6    22          1         1\n",
       "3  2016      8        4    15         12       225\n",
       "4  2016      8        5     9          6       219\n",
       "5  2016     11        5    10          5       310\n",
       "6  2016      8        2     0         31       244\n",
       "7  2016      8        2    13          3       216\n",
       "8  2016      9        1    22         13       257\n",
       "9  2016      9        5    18         24       268"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Year', 'Month', 'Weekday', 'Hour', 'Month_Day', 'Year_Day']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Text based features \n",
    "\n",
    "Features extracted from proposal essay text and resources description\n",
    "\n",
    "- **Feature 21: Length of Essay 1** - total number of characters in essay 1 including spaces\n",
    "- **Feature 22: Length of Essay 2** - total number of characters in essay 2 including spaces\n",
    "- **Feature 23: Length of Essay 3** - total number of characters in essay 3 including spaces\n",
    "- **Feature 24: Length of Essay 4** - total number of characters in essay 4 including spaces\n",
    "- **Feature 25: Length of Project Title** - total number of characters in project title including spaces\n",
    "- **Feature 26: Word Count in the Complete Essay** - total number of words in the complete essay text\n",
    "- **Feature 27: Character Count in the Complete Essay** - total number of characters in complete essay text\n",
    "- **Feature 28: Word Density of the Complete Essay** - average length of the words used in the essay\n",
    "- **Feature 29: Puncutation Count in the Complete Essay** - total number of punctuation marks in the essay\n",
    "- **Feature 30: Upper Case Count in the Complete Essay** - total number of upper count words in the essay\n",
    "- **Feature 31: Title Word Count in the Complete Essay** - total number of proper case (title) words in the essay\n",
    "- **Feature 32: Stopword Count in the Complete Essay** - total number of stopwords in the essay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillup empty values with missing token \n",
    "df['project_essay_3'] = df['project_essay_3'].fillna(missing_token)\n",
    "df['project_essay_4'] = df['project_essay_4'].fillna(missing_token)\n",
    "\n",
    "# extract length of each essay and title\n",
    "df[\"essay1_len\"] = df['project_essay_1'].apply(len)\n",
    "df[\"essay2_len\"] = df['project_essay_2'].apply(len)\n",
    "df[\"essay3_len\"] = df['project_essay_3'].apply(len)\n",
    "df[\"essay4_len\"] = df['project_essay_4'].apply(len)\n",
    "df[\"title_len\"] = df['project_title'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay1_len</th>\n",
       "      <th>essay2_len</th>\n",
       "      <th>essay3_len</th>\n",
       "      <th>essay4_len</th>\n",
       "      <th>title_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>967</td>\n",
       "      <td>805</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>587</td>\n",
       "      <td>639</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>761</td>\n",
       "      <td>546</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201</td>\n",
       "      <td>1209</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>451</td>\n",
       "      <td>556</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>492</td>\n",
       "      <td>737</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>789</td>\n",
       "      <td>931</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>458</td>\n",
       "      <td>629</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>573</td>\n",
       "      <td>774</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>624</td>\n",
       "      <td>710</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay1_len  essay2_len  essay3_len  essay4_len  title_len\n",
       "0         967         805           5           5         24\n",
       "1         587         639           5           5         22\n",
       "2         761         546           5           5         21\n",
       "3        1201        1209           5           5         72\n",
       "4         451         556           5           5         48\n",
       "5         492         737           5           5         37\n",
       "6         789         931           5           5         21\n",
       "7         458         629           5           5         36\n",
       "8         573         774           5           5         37\n",
       "9         624         710           5           5         27"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['essay1_len', 'essay2_len', 'essay3_len', 'essay4_len', 'title_len']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the project essays to create a complete essay text\n",
    "df['text'] = df.apply(lambda row: ' '.join([str(row['project_essay_1']), \n",
    "                                            str(row['project_essay_2']), \n",
    "                                            str(row['project_essay_3']), \n",
    "                                            str(row['project_essay_4'])]), axis=1)\n",
    "\n",
    "# extract features from text\n",
    "df['char_count'] = df['text'].apply(len)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "df['word_density'] = df['char_count'] / (df['word_count']+1)\n",
    "df['punctuation_count'] = df['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in punctuation))) \n",
    "df['title_word_count'] = df['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "df['upper_case_word_count'] = df['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "df['stopword_count'] = df['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.lower() in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1785</td>\n",
       "      <td>314</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1239</td>\n",
       "      <td>192</td>\n",
       "      <td>6.419689</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1320</td>\n",
       "      <td>236</td>\n",
       "      <td>5.569620</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2423</td>\n",
       "      <td>388</td>\n",
       "      <td>6.228792</td>\n",
       "      <td>77</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>187</td>\n",
       "      <td>5.425532</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1242</td>\n",
       "      <td>194</td>\n",
       "      <td>6.369231</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1733</td>\n",
       "      <td>282</td>\n",
       "      <td>6.123675</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1100</td>\n",
       "      <td>184</td>\n",
       "      <td>5.945946</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1360</td>\n",
       "      <td>239</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1347</td>\n",
       "      <td>240</td>\n",
       "      <td>5.589212</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0        1785         314      5.666667                 40                21   \n",
       "1        1239         192      6.419689                 38                15   \n",
       "2        1320         236      5.569620                 26                26   \n",
       "3        2423         388      6.228792                 77                31   \n",
       "4        1020         187      5.425532                 15                13   \n",
       "5        1242         194      6.369231                 54                21   \n",
       "6        1733         282      6.123675                 43                23   \n",
       "7        1100         184      5.945946                 45                16   \n",
       "8        1360         239      5.666667                 31                11   \n",
       "9        1347         240      5.589212                 36                16   \n",
       "\n",
       "   upper_case_word_count  stopword_count  \n",
       "0                      7               5  \n",
       "1                      5               7  \n",
       "2                      6               3  \n",
       "3                      6               4  \n",
       "4                      2               1  \n",
       "5                      5               4  \n",
       "6                      5               2  \n",
       "7                      2               1  \n",
       "8                      6               5  \n",
       "9                     10              10  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['char_count', 'word_count', 'word_density', 'punctuation_count', 'title_word_count', 'upper_case_word_count', 'stopword_count']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. More NLP based features \n",
    "\n",
    "Part of Speech and Sentiment related features from the text. I have used python's textblob package to get the sentiment related features and part-of-speech tags of the tokens in the sentence. \n",
    "\n",
    "- **Feature 33: Article Polarity** - total number of characters in essay 1 including spaces\n",
    "- **Feature 34: Article Subjectivity** - total number of characters in essay 2 including spaces\n",
    "- **Feature 35: Noun Count** - total number of characters in essay 3 including spaces\n",
    "- **Feature 36: Verb Count** - total number of characters in essay 4 including spaces\n",
    "- **Feature 37: Adjective Count** - total number of characters in project title including spaces\n",
    "- **Feature 38: Adverb Count** - total number of words in the complete essay text\n",
    "- **Feature 39: Pronoun Count** - total number of characters in complete essay text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get polatiy and subjectivity of text using the module textblob\n",
    "def get_polarity(text):\n",
    "    try:\n",
    "        textblob = TextBlob(unicode(text, 'utf-8'))\n",
    "        pol = textblob.sentiment.polarity\n",
    "    except:\n",
    "        pol = 0.0\n",
    "    return pol\n",
    "\n",
    "def get_subjectivity(text):\n",
    "    try:\n",
    "        textblob = TextBlob(unicode(text, 'utf-8'))\n",
    "        subj = textblob.sentiment.subjectivity\n",
    "    except:\n",
    "        subj = 0.0\n",
    "    return subj\n",
    "\n",
    "\n",
    "# change df_small to df to create these features on complete dataframe\n",
    "df['polarity'] = df['text'].apply(get_polarity)\n",
    "df['subjectivity'] = df['text'].apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213402</td>\n",
       "      <td>0.391136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192889</td>\n",
       "      <td>0.597111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.353888</td>\n",
       "      <td>0.534450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175880</td>\n",
       "      <td>0.416224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.285417</td>\n",
       "      <td>0.557192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.325781</td>\n",
       "      <td>0.476042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.292540</td>\n",
       "      <td>0.522572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.249625</td>\n",
       "      <td>0.557833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.163784</td>\n",
       "      <td>0.426190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.480667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  subjectivity\n",
       "0  0.213402      0.391136\n",
       "1  0.192889      0.597111\n",
       "2  0.353888      0.534450\n",
       "3  0.175880      0.416224\n",
       "4  0.285417      0.557192\n",
       "5  0.325781      0.476042\n",
       "6  0.292540      0.522572\n",
       "7  0.249625      0.557833\n",
       "8  0.163784      0.426190\n",
       "9  0.223000      0.480667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['polarity', 'subjectivity']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dic = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def pos_check(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_dic[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "# change df_small to df in all of the following lines to create features on complete data frame \n",
    "df['noun_count'] = df['text'].apply(lambda x: pos_check(x, 'noun'))\n",
    "df['verb_count'] = df['text'].apply(lambda x: pos_check(x, 'verb'))\n",
    "df['adj_count'] = df['text'].apply(lambda x: pos_check(x, 'adj'))\n",
    "df['adv_count'] = df['text'].apply(lambda x: pos_check(x, 'adv'))\n",
    "df['pron_count'] = df['text'].apply(lambda x: pos_check(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun_count  verb_count  adj_count  adv_count  pron_count\n",
       "0          81          58         25         16          36\n",
       "1          59          27         25         10          19\n",
       "2          58          51         19          7          32\n",
       "3         105          78         37         23          34\n",
       "4          44          33         18          9          23\n",
       "5          56          38         15          9          25\n",
       "6          80          47         32         14          27\n",
       "7          53          39         19          6          18\n",
       "8          58          49         20          9          24\n",
       "9          67          43         21          4          22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. TF-IDF Features\n",
    "\n",
    "Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency (TF), the second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears.\n",
    "\n",
    "- TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "- IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
    "\n",
    "Reference: http://www.tfidf.com/\n",
    "\n",
    "\n",
    "\n",
    "- **Feature 40:** Word Level N-Gram TF-IDF of Article Text\n",
    "- **Feature 41:** Word Level N-Gram TF-IDF of Project Title\n",
    "- **Feature 42:** Word Level N-Gram TF-IDF of Resource Text\n",
    "- **Feature 43:** Character Level N-Gram TF-IDF of Article Text\n",
    "- **Feature 44:** Character Level N-Gram TF-IDF of Project Title\n",
    "- **Feature 45:** Character Level N-Gram TF-IDF of Resource Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 11,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "df['article_text'] = df.apply(lambda row: ' '.join([str(row['project_essay_1']), str(row['project_essay_2']), \n",
    "                                         str(row['project_essay_3']), str(row['project_essay_4'])]), axis=1)\n",
    "df['resource_text'] = df.apply(lambda row: ' '.join([str(row['resource_description']), str(row['project_resource_summary'])]), axis=1)\n",
    "\n",
    "resource_text = list(df['resource_text'].values)\n",
    "title_text = list(df['project_title'].values)\n",
    "article_text = list(df['article_text'].values)\n",
    "\n",
    "# word level tf-idf for article text\n",
    "vect_word = TfidfVectorizer(max_features=2500, analyzer='word', stop_words='english', ngram_range=(1,3), dtype=np.float32) \n",
    "vect_word.fit(article_text)\n",
    "tfidf_complete = vect_word.transform(article_text)\n",
    "\n",
    "# word level tf-idf for project title\n",
    "vect_word = TfidfVectorizer(max_features=500, analyzer='word', stop_words='english', ngram_range=(1,3), dtype=np.float32) \n",
    "vect_word.fit(title_text)\n",
    "tfidf_title = vect_word.transform(title_text)\n",
    "\n",
    "# word level tf-idf for resource text\n",
    "vect_word = TfidfVectorizer(max_features=1000, analyzer='word', stop_words='english', ngram_range=(1,3), dtype=np.float32) \n",
    "vect_word.fit(resource_text)\n",
    "tfidf_resource = vect_word.transform(resource_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a dictionary mapping the tokens to their tfidf values\n",
    "tfidf = dict(zip(vect_word.get_feature_names(), vect_word.idf_))\n",
    "tfidf = pd.DataFrame(columns=['title_word_tfidf']).from_dict(dict(tfidf), orient='index')\n",
    "tfidf.columns = ['title_word_tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_word_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>measuring worms</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carrying case</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level beginning</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>striped</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit apple</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dice</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>giant clear</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoding</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neck striped</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wi fi silver</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title_word_tfidf\n",
       "measuring worms          4.921973\n",
       "carrying case            4.921973\n",
       "level beginning          4.921973\n",
       "striped                  4.921973\n",
       "fit apple                4.921973\n",
       "dice                     4.921973\n",
       "giant clear              4.921973\n",
       "decoding                 4.921973\n",
       "neck striped             4.921973\n",
       "wi fi silver             4.921973"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features with highest tf-idf (in title)\n",
    "tfidf.sort_values(by=['title_word_tfidf'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly Generating Character Level TF-IDF\n",
    "\n",
    "# character level tf-idf for article text\n",
    "char_word = TfidfVectorizer(max_features=2000, analyzer='char', stop_words='english', ngram_range=(1,3), dtype=np.float32) \n",
    "char_word.fit(article_text)\n",
    "tfidf_complete_char = char_word.transform(article_text)\n",
    "\n",
    "# character level tf-idf for project title\n",
    "char_word = TfidfVectorizer(max_features=500, analyzer='char', stop_words='english', ngram_range=(1,3), dtype=np.float32) \n",
    "char_word.fit(title_text)\n",
    "tfidf_title_char = char_word.transform(title_text)\n",
    "\n",
    "# character level tf-idf for resource text\n",
    "char_word = TfidfVectorizer(max_features=600, analyzer='char', stop_words='english', ngram_range=(1,3), dtype=np.float32) \n",
    "char_word.fit(resource_text)\n",
    "tfidf_resource_char = char_word.transform(resource_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Word Embeddings\n",
    "\n",
    "**Feature 46:** WordEmbedding Vectors of text data\n",
    "\n",
    "Word Embedding Vectors can be trained itself using the corpus or they can be generated using Pre-Trained word embeddings. \n",
    "\n",
    "A word embedding is a class of approaches for representing words and documents using a dense vector representation. It is an improvement over more the traditional bag-of-word model encoding schemes where large sparse vectors were used to represent each word or to score each word within a vector to represent an entire vocabulary. These representations were sparse because the vocabularies were vast and a given word or document would be represented by a large vector comprised mostly of zero values. Instead, in an embedding, words are represented by dense vectors where a vector represents the projection of the word into a continuous vector space. The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used.\n",
    "\n",
    "Reference: https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = df.text.values\n",
    "\n",
    "# load the pre-trained word-vectors\n",
    "embeddings_index = {}\n",
    "f = open('data/wiki-news-300d-1M.vec')\n",
    "for line in f:\n",
    "    if run_for_small_data and len(embeddings_index) == 100:\n",
    "      break\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "# perform pre-processing in keras\n",
    "max_features = 100000 # max number of words to use in word embedding matrix\n",
    "max_len = 300 # max length of the word embedding vector\n",
    "\n",
    "# Tokenization of text data\n",
    "token = text.Tokenizer(num_words=max_features)\n",
    "token.fit_on_texts(list(xtrain))\n",
    "word_index = token.word_index\n",
    "\n",
    "# Create sequence of Tokens and Pad them to create equal length vectors\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "\n",
    "# Create an embedding matrix of words in the data\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Word Embedding Features\n",
    "\n",
    "**Option 1:** Create Sentence Vectors\n",
    "\n",
    "There are differet methods to get the sentence vectors :\n",
    "\n",
    "- Doc2Vec : Train your dataset using Doc2Vec and then use the sentence vectors.\n",
    "- Average of Word2Vec vectors : Take the average of all the word vectors in a sentence. This average vector will represent the sentence vector. In this notebook I have used this approach. \n",
    "- Average of Word2Vec vectors with TF-IDF : Take the word vectors, multiply it with their TF-IDF scores and take the average to get sentence vector.\n",
    "\n",
    "\n",
    "**Option 2:** Use Word Embeddings Directly\n",
    "\n",
    "Keras offers an Embedding layer that can be used for neural networks on text data. It requires that the input data be integer encoded, so that each word is represented by a unique integer. This data preparation step can be performed using the Tokenizer API also provided with Keras. The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option One: Create Sentence to vector\n",
    "    \n",
    "# function to generate sentence vector of the sentence\n",
    "def sent2vec(sentence):\n",
    "    M = []\n",
    "    for w in word_tokenize(unicode(sentence, 'utf8')):\n",
    "        if not w.isalpha():\n",
    "            continue\n",
    "        if w in embeddings_index:\n",
    "            M.append(embeddings_index[w])\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())\n",
    "\n",
    "xtrain_vector = [sent2vec(x) for x in xtrain[:10]]\n",
    "xtrain_vector = np.array(xtrain_vector)\n",
    "\n",
    "# Option Two: Use the word embeddings directly in deep neural network\n",
    "\n",
    "input_layer = Input((max_len, ))\n",
    "embedding_layer = Embedding(len(word_index)+1, max_len, weights=[embedding_matrix], trainable=False)(input_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00789034,  0.0047614 , -0.02462805, ...,  0.15600182,\n",
       "         0.01190511, -0.0175844 ],\n",
       "       [ 0.00342624,  0.01427402, -0.02023149, ...,  0.14776844,\n",
       "         0.02134334, -0.02042206],\n",
       "       [-0.00314885,  0.00978466, -0.03558655, ...,  0.15831296,\n",
       "         0.01724629, -0.02244028],\n",
       "       ...,\n",
       "       [-0.01125617,  0.01371953, -0.02942248, ...,  0.15890415,\n",
       "        -0.00869204, -0.01752197],\n",
       "       [-0.00666285,  0.01355447, -0.02395103, ...,  0.16018023,\n",
       "         0.0209114 , -0.0239821 ],\n",
       "       [ 0.00047431,  0.01163381, -0.02081151, ...,  0.1579946 ,\n",
       "         0.02330043, -0.02554562]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these word vectors can be directly used in the model\n",
    "xtrain_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Topic Modelling Features\n",
    "\n",
    "**Feature 47:** Topic Modelling Features \n",
    "\n",
    "I have used LDA for generating Topic Modelling Features. Latent Dirichlet Allocation (LDA) is an algorithm used to discover the hidden topics that are present in a corpus. LDA starts from a fixed number of topics. Each topic is represented as a distribution over words, and each document is then represented as a distribution over topics. Although the tokens themselves are meaningless, the probability distributions over words provided by the topics provide a sense of the different ideas contained in the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create count vectorizer first\n",
    "cvectorizer = CountVectorizer(min_df=4, max_features=4000, ngram_range=(1,2))\n",
    "cvz = cvectorizer.fit_transform(df['text'])\n",
    "\n",
    "# generate topic models using Latent Dirichlet Allocation\n",
    "lda_model = LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20, random_state=42)\n",
    "X_topics = lda_model.fit_transform(cvz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: and | to | students | they | are | my | the | my students | as | is\n",
      "Topic 1: to | and | students | with | in | the | for | is | have | that\n",
      "Topic 2: and | to | students | of | in | the | their | is | my | have\n",
      "Topic 3: to | students | the | of | and | in | my | for | their | my students\n",
      "Topic 4: the | they | will | and | that | they will | of | to | students | nwe\n",
      "Topic 5: and | new students | of | students | is | same | future | because | each of | to\n",
      "Topic 6: and | to | students | the | of | in | my | our | classroom | for\n",
      "Topic 7: the | of | and have | each | of the | they | high | being | teachers | on\n",
      "Topic 8: to | and | students | my | the | in | they | are | for | will\n",
      "Topic 9: work and | outside | will use | play | allow us | struggles | enjoy | so much | out of | opportunities to\n",
      "Topic 10: to | the | their | sight | students | words | and | they | sight words | of\n",
      "Topic 11: and | the | students | to | in | of | with | our | my | be\n",
      "Topic 12: to | the | of | students | and | my | for | their | that | is\n",
      "Topic 13: to | and | the | students | of | in | my | are | they | their\n",
      "Topic 14: in | school | will | the | for | attend | hope | with | learn | they\n",
      "Topic 15: and | the | students | to | of | my | in | for | is | with\n",
      "Topic 16: within | school year | paper | endless | with the | disabilities | to the | is so | help my | from\n",
      "Topic 17: in | can be | love | or | fun and | the | very | highly | to | still\n",
      "Topic 18: limited | with the | had | progress | been | know | also be | during | and write | and need\n",
      "Topic 19: to | and | students | in | for | the | of | their | are | my\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "\n",
    "# get topics and topic terms\n",
    "topic_word = lda_model.components_ \n",
    "vocab = cvectorizer.get_feature_names()\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))\n",
    "    print('Topic {}: {}'.format(i, ' | '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.27226463e-04, 1.27226463e-04, 1.27226463e-04, 1.27226463e-04,\n",
       "        1.27226463e-04, 1.27226463e-04, 1.27226463e-04, 1.27226463e-04,\n",
       "        1.27226463e-04, 1.27226463e-04, 7.54677204e-01, 1.27226463e-04,\n",
       "        1.27226463e-04, 2.43032719e-01, 1.27226463e-04, 1.27226463e-04,\n",
       "        1.27226463e-04, 1.27226463e-04, 1.27226463e-04, 1.27226463e-04],\n",
       "       [2.67379679e-04, 2.67379679e-04, 2.67379679e-04, 2.67379679e-04,\n",
       "        2.67379679e-04, 2.67379679e-04, 2.67379679e-04, 2.67379679e-04,\n",
       "        2.67379680e-04, 2.67379679e-04, 2.67379681e-04, 2.67379679e-04,\n",
       "        2.67379679e-04, 9.94919786e-01, 2.67379679e-04, 2.67379679e-04,\n",
       "        2.67379679e-04, 2.67379679e-04, 2.67379679e-04, 2.67379679e-04],\n",
       "       [1.83150183e-04, 1.83150183e-04, 1.83150183e-04, 1.83150183e-04,\n",
       "        1.83150183e-04, 1.83150183e-04, 1.83150183e-04, 1.83150183e-04,\n",
       "        1.83150183e-04, 1.83150183e-04, 1.83150185e-04, 1.83150183e-04,\n",
       "        1.83150183e-04, 9.96520147e-01, 1.83150183e-04, 1.83150183e-04,\n",
       "        1.83150183e-04, 1.83150183e-04, 1.83150183e-04, 1.83150183e-04],\n",
       "       [1.07526882e-04, 1.07526882e-04, 1.07526882e-04, 1.07526882e-04,\n",
       "        1.07526882e-04, 1.07526882e-04, 1.07526882e-04, 1.07526882e-04,\n",
       "        1.07526882e-04, 1.07526882e-04, 1.07526883e-04, 1.07526882e-04,\n",
       "        1.07526882e-04, 9.97956989e-01, 1.07526882e-04, 1.07526882e-04,\n",
       "        1.07526882e-04, 1.07526882e-04, 1.07526882e-04, 1.07526882e-04],\n",
       "       [2.59067358e-04, 2.59067358e-04, 2.59067358e-04, 2.59067358e-04,\n",
       "        2.59067358e-04, 2.59067358e-04, 2.59067358e-04, 2.59067358e-04,\n",
       "        2.59067358e-04, 2.59067358e-04, 2.59067360e-04, 2.59067358e-04,\n",
       "        2.59067358e-04, 9.95077720e-01, 2.59067358e-04, 2.59067358e-04,\n",
       "        2.59067358e-04, 2.59067358e-04, 2.59067358e-04, 2.59067358e-04]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_topics[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note that the quality of Word Embeddings and Topic Modelling Features \n",
    "will be poor in case of small data run, but they are improved if the models are run on complete data frame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Count Features\n",
    "\n",
    "**Feature 48 - 60:** Count Features \n",
    "\n",
    "There are some categorical features in the dataset, which can be represented as the count features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_count = ['school_state', 'teacher_id', 'teacher_prefix', 'project_grade_category', 'project_subject_categories', 'project_subject_subcategories']\n",
    "features_for_count += ['Year', 'Year_Day', 'Weekday', 'Month_Day', 'Month', 'Hour']\n",
    "for col in features_for_count:\n",
    "    aggDF = df.groupby(col).agg('count')\n",
    "    aggDF[col] = aggDF.index\n",
    "    tempDF = pd.DataFrame(aggDF[['project_submitted_datetime', col]], columns = ['project_submitted_datetime', col])\n",
    "    tempDF = tempDF.rename(columns={'project_submitted_datetime': col+\"_count\"})\n",
    "    df = df.merge(tempDF, on=col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state_count</th>\n",
       "      <th>teacher_id_count</th>\n",
       "      <th>teacher_prefix_count</th>\n",
       "      <th>project_grade_category_count</th>\n",
       "      <th>project_subject_categories_count</th>\n",
       "      <th>project_subject_subcategories_count</th>\n",
       "      <th>Year_count</th>\n",
       "      <th>Year_Day_count</th>\n",
       "      <th>Weekday_count</th>\n",
       "      <th>Month_Day_count</th>\n",
       "      <th>Month_count</th>\n",
       "      <th>Hour_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_state_count  teacher_id_count  teacher_prefix_count  \\\n",
       "0                   1                 1                    33   \n",
       "1                   4                 1                    51   \n",
       "2                   2                 1                    33   \n",
       "3                   9                 1                    13   \n",
       "4                  11                 1                    13   \n",
       "5                   1                 1                    51   \n",
       "6                   6                 1                    51   \n",
       "7                   5                 1                    51   \n",
       "8                   4                 1                    33   \n",
       "9                   6                 1                    51   \n",
       "\n",
       "   project_grade_category_count  project_subject_categories_count  \\\n",
       "0                            53                                23   \n",
       "1                            24                                 1   \n",
       "2                            24                                 5   \n",
       "3                            24                                 7   \n",
       "4                            13                                 7   \n",
       "5                            53                                 5   \n",
       "6                            53                                 7   \n",
       "7                            53                                 5   \n",
       "8                            13                                15   \n",
       "9                            53                                23   \n",
       "\n",
       "   project_subject_subcategories_count  Year_count  Year_Day_count  \\\n",
       "0                                   11          66               2   \n",
       "1                                    1          34               1   \n",
       "2                                    1          34               1   \n",
       "3                                    6          66               1   \n",
       "4                                    6          66               1   \n",
       "5                                    1          66               1   \n",
       "6                                    6          66               2   \n",
       "7                                    1          66               2   \n",
       "8                                    5          66               1   \n",
       "9                                   11          66               3   \n",
       "\n",
       "   Weekday_count  Month_Day_count  Month_count  Hour_count  \n",
       "0             16                5            5           5  \n",
       "1             19                7            5           6  \n",
       "2             10                5           12           7  \n",
       "3             16                5           16           6  \n",
       "4              9                4           16           2  \n",
       "5              9                4            5           4  \n",
       "6             19                4           16           2  \n",
       "7             19                3           16           9  \n",
       "8             12                3           10           7  \n",
       "9              9                7           10           6  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[x+\"_count\" for x in features_for_count]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
